{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "222a06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "979fe3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"artifacts/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7891a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='f57eb259-9391-4afe-8272-4cd6a957aa66', embedding=None, metadata={'page_label': '1', 'file_name': 'Abdullah Bin Noor Tazim - CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG based Chatbot\\\\artifacts\\\\Abdullah Bin Noor Tazim - CV.pdf', 'file_type': 'application/pdf', 'file_size': 138610, 'creation_date': '2025-11-16', 'last_modified_date': '2025-10-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Abdullah Bin Noor Tazim\\nMachine Learning Engineer\\n♂phone+880-1602584611/envel⌢peabdullah_tazim@outlook.com/gl⌢bePortfolio/linkedinLinkedIn/githubGitHub\\nProfessional Summary\\nFinal-year Computer Science student with hands-on experience in data-driven problem solving and end-to-end\\nmachine learning workflows. Skilled in data preprocessing, statistical analysis, feature engineering, and building\\npredictivemodelsusingPythonandmodernMLframeworks. Experiencedindeployingdata-poweredapplications\\nwith FastAPI and Docker. Passionate about uncovering insights from complex datasets and leveraging data to\\ndrive intelligent decision-making.\\nSkills Summary\\nProgramming:Python, C\\nMachine Learning & AI:PyTorch, TensorFlow, Scikit-learn, Hugging Face.\\nNLP & LLMs:LangChain, RAG , ChromaDB, Ollama\\nDevOps & Deployment:Docker, AWS (EC2), Flask, FastAPI\\nData Tools:Pandas, NumPy, Matplotlib, Seaborn\\nProject Management & Version Control:Git, GitHub, Jira, Notion, Trello.\\nWork Experience\\nElvvo Pathways (Remote, Kairo, Egypt)Oct 2025 – Present\\nNLP Engineer Intern\\n•Develops and optimizes language models for tasks such as text classification, topic modeling, sentiment\\nanalysis, and summarization.\\n•Designs end-to-end NLP pipelines, including data cleaning, tokenization, lemmatization, embedding gener-\\nation, and model deployment.\\n•Apply machine learning and deep learning techniques (e.g. LSTM, Transformers, BERT) to extract insights\\nfrom unstructured text data.\\n•Evaluates and fine-tunes models using metrics like accuracy, F1-score, ROUGE, and Coherence to ensure\\nreliability and interpretability..\\n•Builds scalable, production-ready NLP systems using frameworks such as Hugging Face, spaCy, TensorFlow,\\nand PyTorch.\\nCodeAlpha (Remote, Lucknow, India)Aug 2025– Present\\nMachine Learning Intern\\n•Developed and fine-tuned machine learning models using Python, using libraries such as Scikit-learn, Pandas,\\nand NumPy to build robust data-driven solutions.\\n•Multiple algorithms were implemented and compared, including Linear Regression, Decision Trees, and K-\\nNearest Neighbors (KNN), to identify optimal approaches for predictive performance on structured datasets.\\n•Executed comprehensive data pre-processing workflows, including data cleaning, encoding, scaling, outlier\\ndetection, and feature engineering to enhance model accuracy and interpretability.\\n•Conducted model evaluation and performance tuning using metrics such as accuracy, precision, recall, F1-\\nscore, and cross-validation to ensure generalization and reliability.\\n•Collaborated in weekly code reviews and knowledge-sharing sessions with peers and mentors, contributing\\nto continuous improvement, team learning, and adherence to best coding practices.\\nNeurochip Industries Ltd. (Remote, Dhaka, Bangladesh)Jan 2024 – March 2024\\nTrainee\\n•Assisted in the design and development of internal ERP modules for inventory, HR, and task management.\\n•Contributed to testing and debugging core functionalities to ensure system reliability.\\n•Used Jira for sprint planning, task tracking, and team collaboration in an Agile environment.\\n1', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ef4383df-eb99-4c17-9b2c-4e6b3c702aa3', embedding=None, metadata={'page_label': '2', 'file_name': 'Abdullah Bin Noor Tazim - CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG based Chatbot\\\\artifacts\\\\Abdullah Bin Noor Tazim - CV.pdf', 'file_type': 'application/pdf', 'file_size': 138610, 'creation_date': '2025-11-16', 'last_modified_date': '2025-10-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Machine Learning Projects\\n•Topic Modeling on News Articles :Built an NLP pipeline using LDA and NMF to extract latent topics\\nfrom 10K+ news articles, achieving Coherence: 0.73 and Topic Diversity: 0.92. Optimized text preprocessing\\n(tokenization, lemmatization, noise filtering) improving topic quality by˜18%. Designed a modular, YAML-\\ndriven pipeline with logging and model registry for reproducible experimentation. Code\\n•Credit Risk Prediction (Ensemble ML: LightGBM + XGBoost) :Built a credit risk prediction\\nsystem using ensemble models (LightGBM + XGBoost), achieving F1-score: 96.1% and AUC ROC: 0.9888,\\nsignificantly improving prediction reliability. Reduced false negatives by 16%, directly enhancing detection of\\nhigh-risk borrowers and lowering potential default exposure. Designed a robust preprocessing pipeline (cate-\\ngorical encoding, missing value imputation, risk binning) that improved F1 by +8%, yielding a 14% lift vs.\\nbaseline models. Developed a production-ready ML pipeline (ETL→training→evaluation→deployment),\\nmaking it suitable for fintech loan approval systems . Code\\n•Text Summarization Using Pretrained Transformers :Built an abstractive summarization system us-\\ning BART and T5, generating concise summaries from long documents. Improved model performance by 20%\\n, retaining key information while reducing content length by˜30%. Implemented an optimized preprocessing\\nand tokenization pipeline for efficient model input and fast experimentation. Code\\n•Alzheimer Disease Detection Using Hybrid CNN–Quantum Neural Network :Designed a hybrid\\nlearning framework integrating PQCs with classical neural layers for Alzheimer’s disease classification. Uti-\\nlized rotation-based quantum encoding and CZ entanglement to capture complex feature correlations beyond\\nclassical limits. Achieved 98% overall accuracy, improving classification stability by +5% compared to baseline\\nCNNs. Leveraged TensorFlow + Qiskit integration for hybrid training and quantum parameter optimization\\n. Code\\n•Heart Disease Risk Prediction :Built a stacked ensemble classifier (Random Forest, Logistic Regression,\\nGradient Bosting) achieving AUC-ROC: 0.97, F1: 0.95, and Recall: 94% . Boosted F1 by˜14% over baseline\\nthrough pipeline engineering (categorical encoding +4%, imputation +5%, KMeans risk binning +6%) and\\nhyperparameter tuning (+6%). Deployed via Flask for real-time, millisecond-level predictions, enabling seam-\\nless integration into clinical decision support workflows. Code\\n•Student Performance Prediction :Developed a machine learning model to predict student academic\\nperformance using demographic, behavioral, and academic features. Evaluated multiple algorithms Linear\\nRegression, Decision Tree, and others to compare predictive accuracy and generalization ability. Code\\nEducation\\nUniversity of Liberal Arts Bangladesh (ULAB)Feb 2022 – Present\\nBachelor of Science in Computer Science and Engineering (CSE)\\nCGPA:3.48 / 4.00\\nRelevant Courses:\\n•Machine Learning & AI: Machine Learning, Artificial Intelligence, Digital Image Processing\\n•Mathematics & Algorithms:Statistics & Probability, Data Structures & Algorithms, Software Engi-\\nneering\\n•Core Computing:Differential & Integral Calculus, Linear Algebra.\\nReferences\\nMd. Moshiur Rahman\\nLecturer & Chairman\\nDepartment of Software Engineering\\nGazipur Digital University\\nEmail: moshiur0001@bdu.ac.bd\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ad18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.langchain import LangchainEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2235f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a QA asistant .\n",
    " Your goal is to answer question as accurately\n",
    " as possible based on the\n",
    " instruction and context provided .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed11238",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Ongoing Project\\RAG based Chatbot\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "508d8884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 21:27:28,179 - INFO - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n",
      "2025-11-23 21:27:42,665 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# # 1. Load embeddings from LangChain\n",
    "# hf_embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# # 2. Wrap them for LlamaIndex\n",
    "# embed_model = LangchainEmbedding(hf_embed)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"intfloat/e5-large-v2\",\n",
    "    max_length=512,\n",
    "    device=\"cpu\",  # or \"cuda\"\n",
    "    embed_batch_size=32,  # controls batching\n",
    "    # DO NOT pass normalize_embeddings here\n",
    ")\n",
    "\n",
    "# # 3. Load Ollama LLM\n",
    "llm = Ollama(model=\"llama3.2:1b\",system_prompt=system_prompt)\n",
    "\n",
    "# 4. Load your documents\n",
    "# docs = SimpleDirectoryReader(\"artifacts/\").load_data()\n",
    "\n",
    "\n",
    "Settings.chunk_size = 512\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# 5. Build the vector index\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91c4c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.14.8\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: \n",
      "Author-email: Jerry Liu <jerry@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: G:\\Ongoing Project\\RAG based Chatbot\\venv\\Lib\\site-packages\n",
      "Requires: llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16570586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 64\n",
    "Settings.llm_temperature = 0.2\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.similarity_top_k = 5\n",
    "Settings.response_mode = \"compact\"\n",
    "Settings.node_postprocessors = [SimilarityPostprocessor(similarity_cutoff=0.40)]\n",
    "# Settings.text_splitter = SemanticSplitter(chunk_size=900, chunk_overlap=32)\n",
    "Settings.system_prompt = \"You are a factual assistant. Use only the retrieved data to answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "58404768",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c60c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-23 21:29:23,484 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abdullah Bin Noor Tazim has two work experiences:\n",
      "\n",
      "1. Trainee at Neurochip Industries Ltd., Dhaka, Bangladesh (January 2024 - March 2024)\n",
      "2. NLP Engineer Intern at Elvvo Pathways, Remote, Kairo, Egypt (October 2025 - Present)\n"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what are the work experience mentioned in the tazim's CV?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
