{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "222a06db",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'llama_index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mllama_index\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'llama_index'"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "979fe3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = SimpleDirectoryReader(\"artifacts/\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7891a3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='a9d6e1a0-a35a-4cbf-8121-eb96ef1cdb3c', embedding=None, metadata={'page_label': '1', 'file_name': 'Abdullah Bin Noor Tazim - CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Abdullah Bin Noor Tazim - CV.pdf', 'file_type': 'application/pdf', 'file_size': 138610, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Abdullah Bin Noor Tazim\\nMachine Learning Engineer\\n♂phone+880-1602584611/envel⌢peabdullah_tazim@outlook.com/gl⌢bePortfolio/linkedinLinkedIn/githubGitHub\\nProfessional Summary\\nFinal-year Computer Science student with hands-on experience in data-driven problem solving and end-to-end\\nmachine learning workflows. Skilled in data preprocessing, statistical analysis, feature engineering, and building\\npredictivemodelsusingPythonandmodernMLframeworks. Experiencedindeployingdata-poweredapplications\\nwith FastAPI and Docker. Passionate about uncovering insights from complex datasets and leveraging data to\\ndrive intelligent decision-making.\\nSkills Summary\\nProgramming:Python, C\\nMachine Learning & AI:PyTorch, TensorFlow, Scikit-learn, Hugging Face.\\nNLP & LLMs:LangChain, RAG , ChromaDB, Ollama\\nDevOps & Deployment:Docker, AWS (EC2), Flask, FastAPI\\nData Tools:Pandas, NumPy, Matplotlib, Seaborn\\nProject Management & Version Control:Git, GitHub, Jira, Notion, Trello.\\nWork Experience\\nElvvo Pathways (Remote, Kairo, Egypt)Oct 2025 – Present\\nNLP Engineer Intern\\n•Develops and optimizes language models for tasks such as text classification, topic modeling, sentiment\\nanalysis, and summarization.\\n•Designs end-to-end NLP pipelines, including data cleaning, tokenization, lemmatization, embedding gener-\\nation, and model deployment.\\n•Apply machine learning and deep learning techniques (e.g. LSTM, Transformers, BERT) to extract insights\\nfrom unstructured text data.\\n•Evaluates and fine-tunes models using metrics like accuracy, F1-score, ROUGE, and Coherence to ensure\\nreliability and interpretability..\\n•Builds scalable, production-ready NLP systems using frameworks such as Hugging Face, spaCy, TensorFlow,\\nand PyTorch.\\nCodeAlpha (Remote, Lucknow, India)Aug 2025– Present\\nMachine Learning Intern\\n•Developed and fine-tuned machine learning models using Python, using libraries such as Scikit-learn, Pandas,\\nand NumPy to build robust data-driven solutions.\\n•Multiple algorithms were implemented and compared, including Linear Regression, Decision Trees, and K-\\nNearest Neighbors (KNN), to identify optimal approaches for predictive performance on structured datasets.\\n•Executed comprehensive data pre-processing workflows, including data cleaning, encoding, scaling, outlier\\ndetection, and feature engineering to enhance model accuracy and interpretability.\\n•Conducted model evaluation and performance tuning using metrics such as accuracy, precision, recall, F1-\\nscore, and cross-validation to ensure generalization and reliability.\\n•Collaborated in weekly code reviews and knowledge-sharing sessions with peers and mentors, contributing\\nto continuous improvement, team learning, and adherence to best coding practices.\\nNeurochip Industries Ltd. (Remote, Dhaka, Bangladesh)Jan 2024 – March 2024\\nTrainee\\n•Assisted in the design and development of internal ERP modules for inventory, HR, and task management.\\n•Contributed to testing and debugging core functionalities to ensure system reliability.\\n•Used Jira for sprint planning, task tracking, and team collaboration in an Agile environment.\\n1', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f53bf670-351e-48f0-b5b2-8c95d6ca9b0e', embedding=None, metadata={'page_label': '2', 'file_name': 'Abdullah Bin Noor Tazim - CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Abdullah Bin Noor Tazim - CV.pdf', 'file_type': 'application/pdf', 'file_size': 138610, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-31'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Machine Learning Projects\\n•Topic Modeling on News Articles :Built an NLP pipeline using LDA and NMF to extract latent topics\\nfrom 10K+ news articles, achieving Coherence: 0.73 and Topic Diversity: 0.92. Optimized text preprocessing\\n(tokenization, lemmatization, noise filtering) improving topic quality by˜18%. Designed a modular, YAML-\\ndriven pipeline with logging and model registry for reproducible experimentation. Code\\n•Credit Risk Prediction (Ensemble ML: LightGBM + XGBoost) :Built a credit risk prediction\\nsystem using ensemble models (LightGBM + XGBoost), achieving F1-score: 96.1% and AUC ROC: 0.9888,\\nsignificantly improving prediction reliability. Reduced false negatives by 16%, directly enhancing detection of\\nhigh-risk borrowers and lowering potential default exposure. Designed a robust preprocessing pipeline (cate-\\ngorical encoding, missing value imputation, risk binning) that improved F1 by +8%, yielding a 14% lift vs.\\nbaseline models. Developed a production-ready ML pipeline (ETL→training→evaluation→deployment),\\nmaking it suitable for fintech loan approval systems . Code\\n•Text Summarization Using Pretrained Transformers :Built an abstractive summarization system us-\\ning BART and T5, generating concise summaries from long documents. Improved model performance by 20%\\n, retaining key information while reducing content length by˜30%. Implemented an optimized preprocessing\\nand tokenization pipeline for efficient model input and fast experimentation. Code\\n•Alzheimer Disease Detection Using Hybrid CNN–Quantum Neural Network :Designed a hybrid\\nlearning framework integrating PQCs with classical neural layers for Alzheimer’s disease classification. Uti-\\nlized rotation-based quantum encoding and CZ entanglement to capture complex feature correlations beyond\\nclassical limits. Achieved 98% overall accuracy, improving classification stability by +5% compared to baseline\\nCNNs. Leveraged TensorFlow + Qiskit integration for hybrid training and quantum parameter optimization\\n. Code\\n•Heart Disease Risk Prediction :Built a stacked ensemble classifier (Random Forest, Logistic Regression,\\nGradient Bosting) achieving AUC-ROC: 0.97, F1: 0.95, and Recall: 94% . Boosted F1 by˜14% over baseline\\nthrough pipeline engineering (categorical encoding +4%, imputation +5%, KMeans risk binning +6%) and\\nhyperparameter tuning (+6%). Deployed via Flask for real-time, millisecond-level predictions, enabling seam-\\nless integration into clinical decision support workflows. Code\\n•Student Performance Prediction :Developed a machine learning model to predict student academic\\nperformance using demographic, behavioral, and academic features. Evaluated multiple algorithms Linear\\nRegression, Decision Tree, and others to compare predictive accuracy and generalization ability. Code\\nEducation\\nUniversity of Liberal Arts Bangladesh (ULAB)Feb 2022 – Present\\nBachelor of Science in Computer Science and Engineering (CSE)\\nCGPA:3.48 / 4.00\\nRelevant Courses:\\n•Machine Learning & AI: Machine Learning, Artificial Intelligence, Digital Image Processing\\n•Mathematics & Algorithms:Statistics & Probability, Data Structures & Algorithms, Software Engi-\\nneering\\n•Core Computing:Differential & Integral Calculus, Linear Algebra.\\nReferences\\nMd. Moshiur Rahman\\nLecturer & Chairman\\nDepartment of Software Engineering\\nGazipur Digital University\\nEmail: moshiur0001@bdu.ac.bd\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='5bbe0f93-fc43-4e3f-96bc-7ce57f486fa8', embedding=None, metadata={'page_label': '', 'file_name': 'Abdullah Tazim - Resume.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Abdullah Tazim - Resume.pdf', 'file_type': 'application/pdf', 'file_size': 231062, 'creation_date': '2025-11-05', 'last_modified_date': '2025-11-03'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Abdullah Bin Noor Tazim\\n♂¶ap-¶arker-altDhaka, Bangladesh ♂phone+8801602584611 /envel⌢peabdullah_tazim@outlook.com /gl⌢bePortfolio /linkedinLinkedIn /githubGitHub\\nSUMMARY\\nFinal-year CS student with hands-on experience in developing and deploying ML/DL solutions using Python, TensorFlow, and Flask.\\nSkilled in building end-to-end AI projects, with experience in PyTorch, Docker, and cloud deployment, delivering scalable data-\\ndriven solutions.\\nSKILLS\\nProgramming: Python, C\\nMachine Learning & AI: PyTorch, TensorFlow, Scikit-learn, Hugging Face\\nNLP & LLMs: LangChain, RAG , ChromaDB, Ollama\\nDeployment & DevOps: Docker, AWS (EC2), Flask, FastAPI\\nData Tools: Pandas, NumPy , Matplotlib, Seaborn\\nProject Management & Version Control:Git, GitHub, Jira, Notion, Trello\\nEXPERIENCE\\nElvvo Pathways (Remote, Kairo, Egypt) (Oct 2025 – Present)\\nNLP Engineer Intern\\n• Apply machine learning and deep learning techniques (e.g. LSTM, Transformers, BERT) to extract insights from unstructured\\ntext data.\\n• Designs end-to-end NLP pipelines, including data cleaning, tokenization, lemmatization, embedding generation, and model de-\\nployment.\\n• Builds scalable, production-ready NLP systems using frameworks such as Hugging Face, spaCy , TensorFlow, and PyTorch.\\nCodeAlpha (Remote, Lucknow, India) (Aug 2025– Present)\\nMachine Learning Intern\\n• Developed and fine-tuned machine learning models using Python, using libraries such as Scikit-learn, Pandas, and NumPy to\\nbuild robust data-driven solutions.\\n• Multiple algorithms were implemented and compared, including Linear Regression, Decision Trees, and K-Nearest Neighbors\\n(KNN), to identify optimal approaches for predictive performance on structured datasets.\\n• Executed comprehensive data pre-processing workflows, including data cleaning, encoding, scaling, outlier detection, and feature\\nengineering to enhance model accuracy and interpretability .\\nNeurochip Industries Ltd. (Remote, Dhaka, Bangladesh) (Jan 2024 – March 2024)\\nTrainee\\n• Assisted in the design and development of internal ERP modules for inventory , HR, and task management.\\n• Contributed to testing and debugging core functionalities to ensure system reliability .\\n• Used Jira for sprint planning, task tracking, and team collaboration in an Agile environment.\\nPROJECTS\\nHybrid Quantum–Classical Learning for Alzheimer’s Classification\\n• Built a PQC-based hybrid neural model for Alzheimer’s classification, leveraging rotation encoding and CZ entanglement for richer\\nfeature learning.\\n• Achieved 98% accuracy with +5% stability gain over CNNs, using only 44K parameters (almost 90% reduction) and 8% higher\\nnoise robustness.\\n• Implemented TensorFlow–Qiskit hybrid training, enabling quantum parameter optimization and 30% faster convergence.\\nText Summarization Using Pretrained Transformers\\n• Built an abstractive summarization system with BART and T5, generating concise, semantically faithful summaries.\\n• Improved performance by 20%, retaining >90% key info and reducing content length by 30% (ROUGE-L, BLEU).\\n• Optimized preprocessing and tokenization, cutting training time by 25% and boosting GPU efficiency by 18%.\\nTopic Modeling on News Articles\\n• Developed an NLP topic modeling pipeline using LDA & NMF on 10K+ articles, achieving Coherence 0.73 and Diversity 0.92..\\n• Optimized preprocessing (tokenization, lemmatization, noise filtering) to improve topic quality by 18%..\\n• Built a modular YAML-driven pipeline with logging & model registry for scalable, reproducible experiments.\\nEDUCATION\\nBachelor in Computer Science and Engineering – University of Liberal Arts Bangladesh (ULAB)\\nCGPA : 3.50 / 4.00\\nExpected 2025', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d20b90f2-eb5c-45cd-9479-89dd6d3a62f8', embedding=None, metadata={'page_label': '1', 'file_name': 'CV_Noman.pdf-1.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\CV_Noman.pdf-1.pdf', 'file_type': 'application/pdf', 'file_size': 222057, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Md. Mutasim Billah Abu Noman Akanda\\nData Scientist · AI Engineer · Machine Learning Engineer\\n/ne+880-1773272649 /g♀bePortfolio Email /♀nednLinkedIn /gtbGitHub\\nProfessional Summary\\n• Data Scientist: 3+ years Experience in building AI-driven solutions for web scraping, fair market valuation, NLP, and\\ncomputer vision applications. Skilled in designing scalable ML models and deploying AI-powered microservices using Docker\\nand FastAPI. Passionate about cutting-edge research in deep learning and large language models.\\nWork Experience\\n• Pixalate Inc. Remote (California, USA)\\nData Scientist Mar 2025 - Aug 2025\\n◦ Assigned Project: Ad Intel Crawler: AI-powered ad network detection system\\n◦ Responsibilities: Developing AI-driven solutions for web crawling, ad network identification, and automated\\nmedia analysis.\\n◦ Top Contributions:\\n∗ Designed and implemented a comprehensive ad network detection system, achieving 73% detection\\naccuracy across 2 millions of diverse websites using Python, Playwright, and custom pattern matching .\\n∗ Built multi-method detection pipeline integrating iframe analysis, URL pattern matching, and frame ID\\ncorrelation, successfully distinguishing between Google AdSense, Ad Manager, and Ads products.\\n∗ Developed modular hook system for browser automation, implementing iframe capture, network monitoring, and\\nclick simulation using Playwright CDP and custom browser hooks .\\n∗ Implemented deterministic pattern matching for ad network identification, eliminating AI dependency while\\nmaintaining high accuracy through rule-based detection algorithms.\\n∗ Built comprehensive testing framework analyzing 89 thousands ads across diverse websites, generating detailed\\nQA reports and identifying improvement opportunities for 15%+ accuracy gains.\\n∗ Designed scalable crawler orchestration system managing media processing, ad detection, and result aggregation\\nusing asynchronous processing and modular architecture .\\n• Green Pants Studio Remote (Texas, USA)\\nAI Engineer June 2024 - May 2025\\n◦ Assigned Project: Vendidit: AI-powered eCommerce intelligence system\\n◦ Responsibilities: Developing AI-driven solutions for web scraping, fair market valuation, and automated data\\nmapping.\\n◦ Top Contributions:\\n∗ Developed and optimized Vendidit Scraper, increasing data extraction speed by 40% using Apify, Scrapy, and\\nPlaywright.\\n∗ Implemented Dockerized microservices, reducing deployment time by 50% via Docker, FastAPI, and AWS\\nECS.\\n∗ Conducted Exploratory Data Analysis (EDA) on scraped datasets, improving data quality insights using\\nPandas, NumPy, and Matplotlib.\\n∗ Trained and fine-tuned an Ordinary Least Squares (OLS) regression model , achieving 92% accuracy using\\nScikit-learn.\\n∗ Deployed ML pipelines to a production server, optimizing inference speed via Uvicorn and FastAPI.\\n∗ Continuously refactored codebases to enhance scalability and maintainability.\\n• Apurba Technologies Ltd. On-site (Dhaka, Bangladesh)\\nMachine Learning Engineer Mar 2023 - May 2024\\n◦ Assigned Project: Bengali OCR (Funded by the ICT Ministry of Bangladesh)\\n◦ Responsibilities: Developing deep learning-based OCR solutions for Bengali text recognition, document layout\\nanalysis, and scene text detection.\\n◦ Top Contributions:\\n∗ Trained and deployed YOLOv8-based Document Layout Analysis (DLA) model for low-resource languages\\nusing Ultralytics and PyTorch.\\n∗ Reduced overlapping segment errors by 30%, improving document structure accuracy via OpenCV-based\\npost-processing.\\n∗ Optimized the DLA model using 8-bit quantization, achieving 2x faster inference speed using TensorRT\\nand ONNX.\\n∗ Developed API testing automation scripts for Postman and JMeter to enhance server performance evaluation.\\n∗ Co-authored research papers, published in ACM SE’24 and Springer, focusing on deep learning-based OCR.\\n∗ Refactored ML pipelines for higher efficiency and modularity , leveraging PyTorch Lightning and MLflow.\\nSkills Summary\\n◦ Programming: Python, C++, C\\n◦ Machine Learning & AI: PyTorch, TensorFlow, Scikit-learn, OpenCV, Hugging Face, Ultralytics, Tesseract, Roboflow\\n◦ NLP & Large Language Models : LangChain, LangGraphRAG, ChromaDB, LanceDB, Ollama, ScrapeGraphAI\\n◦ DevOps & Deployment: Docker, AWS (S3, EC2, ECS, ECR), GCP, Uvicorn, FastAPI\\n◦ Web Scraping: Apify, Playwright, Zyte, BeautifulSoup4, Scrapy, Firecrawl, Crawl4AI, Browser Use\\n◦ Project Management & Version Control: Bitbucket, Git, GitHub, Aha, Jira, Notion, Slack, Trello, Whimsical', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='013ef19d-b888-4b15-b0ac-55ccd587d41b', embedding=None, metadata={'page_label': '2', 'file_name': 'CV_Noman.pdf-1.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\CV_Noman.pdf-1.pdf', 'file_type': 'application/pdf', 'file_size': 222057, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-04'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Education\\n◦\\nUniversity of Liberal Arts Bangladesh (ULAB) Dhaka, Bangladesh\\nBachelor of Science in Computer Science and Engineering (CSE) June 2019 - February 2023\\nAcademic Distinction:Summa Cum Laude (Top 1% of graduating class)\\nCGPA: 3.96 / 4.00\\nHonors: Vice Chancellor’s Honors List, Dean’s List Scholarship (3x)\\nRelevant Courses:\\n∗ Machine Learning & AI: Machine Learning, Artificial Intelligence, Digital Image Processing\\n∗ Mathematics & Algorithms: Statistics & Probability, Data Structures & Algorithms, Software Engineering\\n∗ Core Computing: Differential & Integral Calculus, Linear Algebra, Robotics\\nMachine Learning Projects\\n◦ RAG-based Local Chat Box: Developed a Streamlit-based web application integrating a Local Language Model\\n(LLM) with Retrieval-Augmented Generation (RAG). Users can index documents, create embeddings, and interact with\\ntheir data using state-of-the-art LLMs.\\nTech Stack: Python, ChromaDB, Langchain, Ollama, Pypdf, Pandas, Streamlit\\nGitHub Link: RAG-based Local Chat Box\\n◦ Langchain-based Web Scraping with ScrapeGraphAI: Implemented LLM-powered web scraping with\\nScrapeGraphAI for extracting structured data from any website.\\nTech Stack: Python, ScrapeGraphAI, Langchain, WebKit, Ollama, Playwright\\nGitHub Link: Langchain Web Scraping\\n◦ Parking Spot Tracking: Developed a YOLOv9-based vehicle tracking system using centroid tracking for real-time\\nparking space monitoring.\\nTech Stack: PyTorch, OpenCV, Ultralytics, YOLOv9, Numpy, JSON\\nGitHub Link: Parking Spot Tracking\\n◦ Web Scraper: Created a customizable web scraper that extracts structured data from any webpage based on schema\\ndefinitions.\\nTech Stack: Streamlit, FastAPI, JSON, BeautifulSoup4, Python Requests\\nGitHub Link: Web Scraper\\n◦ Game Addiction Analysis with Neural Network : Built a deep learning model to predict game addiction-related\\nhealth issues using a survey-based dataset. Achieved 80.70% accuracy.\\nTech Stack: TensorFlow, Keras, Scikit-learn, Seaborn, Matplotlib, Numpy, Pandas\\nGitHub Link: Game Addiction Analysis\\nPublications\\n◦ Md. Mutasim Billah Abu Noman Akanda, Maruf Ahmed, AKM Shahariar Azad Rabby, and Fuad\\nRahman.: Optimum Deep Learning Method for Document Layout Analysis in Low Resource Languages . In\\nProceedings of the 2024 ACM Southeast Conference (ACM SE ’24). Association for Computing Machinery, New York, NY,\\nUSA, 199–204. https://doi.org/10.1145/3603287.3651184.\\n◦ Akanda, M.B.A.N., Prodhan, M., Sarwar, S., Raatul, A.M., Paul, B. : Voice Controlled Home Automation\\nwith Cloud-Based Environment Monitoring System . In: Joshi, A., Mahmud, M., Ragel, R.G. (eds) Information and\\nCommunication Technology for Competitive Strategies (ICTCS 2022). ICTCS 2022. Lecture Notes in Networks and\\nSystems, vol 623. Springer, Singapore. https://doi.org/10.1007/978-981-19-9638-2 21.\\nHonors & Awards\\n◦ Summa Cum Laude: (May 2024) - Graduated in the Top 1% of the class.\\n◦ Problem Setter, ULAB Take Off Programming Contest : (Summer 2022) - Designed algorithmic problems for the\\ncontest.\\n◦ Vice Chancellor’s Honors List Scholarship : (Summer 2021) - Recognized for outstanding academic excellence.\\n◦ 2nd Runners Up, ULAB Take Off Programming Contest: (Fall 2021) - Secured 3rd place in a university-wide coding\\ncompetition.\\n◦ Dean’s List Scholarship: (Summer 2020, Fall 2020, Spring 2021) - Achieved consistent academic excellence across\\nmultiple semesters.\\n◦ 1st Runners Up, ULAB Take Off Programming Contest : (Spring 2021) - Ranked 2nd in an intensive\\nproblem-solving contest.\\nReferences\\n◦ Dr. Muhammad Abul Hasan : Associate Professor, Department of CSE, Green University of Bangladesh.\\n muhammad.hasan@cse.green.edu.bd\\n◦ More references available upon request. :', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='289e5bf6-c695-4ae3-90cf-74ba5cf34484', embedding=None, metadata={'page_label': '1', 'file_name': 'Formal_CV_Tamanna_Khatun (1).pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Formal_CV_Tamanna_Khatun (1).pdf', 'file_type': 'application/pdf', 'file_size': 198016, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=' \\nTamanna  Khatun  Savar,  Dhaka,  Bangladesh  t.khatun.info@gmail.com  tamanna.khatun.cse@ulab.edu.bd www.linkedin.com/in/tamanna-khatun-2011s Phone  Number:  01827453830   P\\nROFESSIONAL\\n S\\nUMMARY\\n \\nEngineering  student  with  experience  in  web  development,  machine  learning  projects,  and  a  passion  \\nfor\\n \\nacademic\\n \\nresearch.\\n \\nModerately\\n \\nskilled\\n \\nin\\n \\nprogramming,\\n \\nproblem-solving,\\n \\nand\\n \\nproject\\n \\nmanagement.\\n \\n \\nE\\nDUCATION\\n \\n2022-2026   (Ongoing)  \\nBSc  in  Computer  Science  and  Engineering  Major:  Data  Science  Current  CGPA:  3.91/4.00  \\nUniversity  of  Liberal  Arts  Bangladesh  \\n2020  Higher  Secondary  Certificate  Group:  Science  GPA:  5.00/5.00   \\nAkran  High  School  \\n2018  Secondary  School  Certificate  Group:  Science  GPA:  4.78/5.00  \\nAkran  High  School  \\n E\\nXPERIENCES\\n \\n●  Teaching  Assistant  -  Department  of  Computer  Science  &  Engineering  \\nUniversity  of  Liberal  Arts  Bangladesh  (ULAB)  \\nMay  2025  -  September  2025  \\nT\\nECHNICAL\\n S\\nKILLS\\n \\n●  Programming  Language  ○  C  /  C++  ○  Java  ○  Python   \\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f263b887-052a-4f85-af98-d9f9edbac36b', embedding=None, metadata={'page_label': '2', 'file_name': 'Formal_CV_Tamanna_Khatun (1).pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Formal_CV_Tamanna_Khatun (1).pdf', 'file_type': 'application/pdf', 'file_size': 198016, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='●  Web  Development  ○  HTML  ○  CSS  ○  JavaScript  ○  PHP  \\n●  GUI  ○  PyQT5,  PyQT6  ○  Java  Swing  \\n●  Databases  ○  MySQL  ○  MongoDB  \\n●  Tools  and  Frameworks  ○  Node.js  ○  Express.js  ○  XAMPP  ○  Git/GitHub  \\n●  Documentation  and  Visualization  ○  LaTeX  ○  LucidChart  \\n \\nP\\nROJECTS\\n \\n●  Student  Performance  Prediction  Analysis:  A  machine  learning-based  analysis  project  for  \\npredicting\\n \\nstudent\\n \\nacademic\\n \\nperformance\\n \\nusing\\n \\ndemographic,\\n \\nsocio-economic,\\n \\nand\\n \\nacademic\\n \\nattributes.\\n \\nImplemented\\n \\nclassification\\n \\nand\\n \\nregression\\n \\nmodels,\\n \\nperformed\\n \\nexploratory\\n \\ndata\\n \\nanalysis,\\n \\nevaluated\\n \\nalgorithm\\n \\nperformance\\n \\nwith\\n \\nmetrics,\\n \\nand\\n \\nidentified\\n \\nkey\\n \\nfactors\\n \\ninfluencing\\n \\noutcomes\\n \\nto\\n \\nsupport\\n \\nearly\\n \\ninterventions.\\n \\nGoogle  Colab  Notebook:  [Link]  \\n●  Aromagic  Glow:  A  MERN-stack-based  e-commerce  website  for  customizable  scented  \\ncandles\\n \\nwith\\n \\nfeatures\\n \\nsuch\\n \\nas\\n \\nuser\\n \\nauthentication,\\n \\nproduct\\n \\nbrowsing,\\n \\nsearch/filter,\\n \\nwishlist,\\n \\ncart,\\n \\nand\\n \\ncheckout.\\n \\nImplemented\\n \\na\\n \\ndynamic\\n \\ncustomization\\n \\npanel\\n \\n(size,\\n \\ncolor,\\n \\nscent,\\n \\ndesign)\\n \\nwith\\n \\nreal-time\\n \\nprice\\n \\nupdates,\\n \\nsecure\\n \\ndata\\n \\nmanagement,\\n \\nand\\n \\nresponsive\\n \\ndesign.\\n \\nGitHub:  [Link]  \\n \\n ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='466de8c4-08b3-440f-9221-aad8e4702e1c', embedding=None, metadata={'page_label': '3', 'file_name': 'Formal_CV_Tamanna_Khatun (1).pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Formal_CV_Tamanna_Khatun (1).pdf', 'file_type': 'application/pdf', 'file_size': 198016, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='●  Simple  VCMS:  The  Simple  VCMS  (Veterinary  Clinic  Management  System)  is  an  \\napplication\\n \\nthat\\n \\nefficiently\\n \\nmanages\\n \\na\\n \\nveterinary\\n \\nclinic’s\\n \\ninformation.\\n \\nIt\\n \\nallows\\n \\nclinic\\n \\nstaff\\n \\nto\\n \\ntake\\n \\nappointments\\n \\nand\\n \\nstore\\n \\nthe\\n \\ninformation\\n \\nof\\n \\nanimals\\n \\nand\\n \\ntheir\\n \\nowners.\\n \\nGitHub:  [Link]  \\n●  Pharma  Care:  Pharma  Care  is  a  Java-based  application  for  efficient  pharmaceutical  \\nmanagement,\\n \\nassisting\\n \\npharmacies\\n \\nwith\\n \\ninventory,\\n \\nprescription\\n \\nmanagement,\\n \\nsales\\n \\ntracking,\\n \\nand\\n \\nrecord-keeping.\\n \\nWith\\n \\na\\n \\nuser-friendly\\n \\ninterface\\n \\nand\\n \\nreliable\\n \\nbackend,\\n \\nit\\n \\naddresses\\n \\nkey\\n \\nneeds\\n \\nin\\n \\npharmacy\\n \\noperations,\\n \\nenhancing\\n \\nworkflow\\n \\nand\\n \\naccuracy\\n \\nfor\\n \\nsmall\\n \\nto\\n \\nmedium-sized\\n \\nbusinesses.\\n \\nGitHub:  [Link]  \\n●  Online  Book  Store  Management  System:  The  Online  Book  Store  Management  System  is  a  \\nplatform\\n \\nthat\\n \\nautomates\\n \\nbookstore\\n \\noperations\\n \\nwith\\n \\na\\n \\nuser-friendly\\n \\ninterface\\n \\nfor\\n \\ncustomers\\n \\nand\\n \\nadministrators.\\n \\nIt\\n \\nsupports\\n \\ninventory\\n \\nmanagement,\\n \\norder\\n \\nprocessing,\\n \\nand\\n \\ntransactions,\\n \\nallowing\\n \\neasy\\n \\nbrowsing,\\n \\nsearching,\\n \\nand\\n \\npurchasing\\n \\nof\\n \\nbooks.\\n \\nAdministrators\\n \\ncan\\n \\nseamlessly\\n manage  inventory,  and  the  project,  accessible  on  Replit,  features  a  well-structured  codebase  with  essential  bookstore  functions.  \\nGitHub:  [Link]  \\n \\n \\nR\\nEFERENCES\\n \\n \\nReference  1   Reference  2  \\n \\n“I  CERTIFY  THAT  THE  INFORMATION  STATED  IN  THIS  RESUME  IS  TRUE  AND  \\nCOMPLETE\\n \\nTO\\n \\nTHE\\n \\nBEST\\n \\nOF\\n \\nMY\\n \\nKNOWLEDGE.\\n \\nI\\n \\nAUTHORIZE\\n \\nTHE\\n \\nRECEIVER\\n \\nOF\\n \\nTHIS\\n \\nCV\\n \\nTO\\n \\nVERIFY\\n \\nTHE\\n \\nINFORMATION\\n \\nPROVIDED\\n \\nIN\\n \\nTHIS\\n \\nRESUME”\\n \\n \\nYours  Truly,  \\nTamanna  Khatun  [Placeholder]  \\nSignature  ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f718172a-f1b0-4743-a0f6-773c500ee8aa', embedding=None, metadata={'page_label': '1', 'file_name': 'Mansuba_CV T (1) (1).pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Mansuba_CV T (1) (1).pdf', 'file_type': 'application/pdf', 'file_size': 128969, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Mansuba Tabassum\\nmansubatabassum9@gmail.com | linkedin.com/in/mansuba-tabassum-256b771ba/ | github.com/Mansu123 |\\nPortfolio | +8801858443719\\nEducation\\nUniversity of Liberal Arts Bangladesh Bangladesh,Dhaka\\nBachelor of Science in Computer Science and Engineering, CGPA : 3:19 Aug. 2019 – may 2025\\nExperience\\nImpact Scholars Proposal Reviewer (Deep Learning) Aug 2025 – Present\\nNeuromatch California, USA\\n∗ Reviewing and evaluating research proposals in deep learning, vision-language models, and LLMs from scholars\\nworldwide, supporting innovative AI research and contributing to global scientific impact.\\n∗ Collaborating with an international panel of domain experts to ensure fair, rigorous, and constructive feedback for\\nsubmitted proposals.\\nMachine Learning Fellow Sep 2023 – Apr 2024\\nFellowship.AI California, USA\\n∗ Wrinkle Removal Application: Developed an AI-powered application using Stable Diffusion and ControlNet,\\nintegrated with Mediapipe’s segmentation model, to remove wrinkles from clothing in images in real time.\\n∗ Minor Hair Removal Application: Led the development of an application to remove minor hair from images using\\nControlNet and Stable Diffusion models for precise image enhancement. [Code]\\nDeep Learning Intern Nov 2023 – Jan 2024\\nMentorness Gujarat, India\\n∗ Developed and implemented a deep learning model using computer vision to detect and map facial landmarks for\\nidentity verification and emotion recognition. [Code]\\n∗ Music Popularity Prediction: Created a machine learning model to predict song popularity by analyzing text\\nfeatures and metadata using traditional ML techniques. [Code]\\nDeep Learning & Computational Neuroscience Summer Schools Jul 2023 – Aug 2024\\nStudent Researcher — Neuromatch Academy USA\\n∗ Music Trend Detection: Implemented an NLP-based machine learning model to analyze lyrics and identify music\\ntrends, predicting popular songs based on linguistic patterns. [Code]\\n∗ Reinforcement Learning Behavioral Analysis: Conducted a comparative study of RL agent behavior versus real\\nmice using CNNs, replicating an RL environment from the Steinmetz dataset and generating a synthetic image\\ndataset with OpenCV. [Code]\\nResearch Experience\\n• Interpretable Flow Feature Extraction via Neuron-Guided Sparse Latent Autoencoder: Designed a\\ndeep learning model that extracts key features from fluid dynamics datasets using neuron-guided sparsity,\\nimproving interpretability and enabling efficient analysis of turbulent flows. (Writing Stage)\\n• BanglaCLIP: Developed a vision-language model to learn cross-modal representations for Bangla text and image\\nalignment using contrastive learning techniques. This project bridges semantic understanding between Bangla text\\nand images to improve retrieval and generation tasks. (Writing Stage)\\nProjects\\nML/DL & Development| Python, PyTorch, Keras, NLP, Computer Vision, LangChain, LLM, FastAPI, Java, Flask, Flutter, GitJune 2020 – Present\\n∗ RAG Document Chatbot with FastAPI: Built a production-ready Retrieval-Augmented Generation (RAG)\\nchatbot using FastAPI, LangChain, and Google Gemini AI. Enables intelligent conversations about uploaded\\ndocuments with advanced document processing and contextual understanding. [Code]', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e54a46ac-7b4c-48fa-a2fd-48b06090ab10', embedding=None, metadata={'page_label': '2', 'file_name': 'Mansuba_CV T (1) (1).pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Mansuba_CV T (1) (1).pdf', 'file_type': 'application/pdf', 'file_size': 128969, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='∗ LinkedIn Post Automation with Gemini AI: Developed an automated workflow using Google’s Gemini API\\nand n8n platform to generate and publish engaging LinkedIn posts. Features AI-powered content generation,\\nautomated publishing via LinkedIn API v2, and secure authentication handling. [Code]\\n∗ Bangla Text-to-Image Generation: Developing a Few-Shot Diffusion Model for generating Bangla\\ntext-to-image outputs, while building a custom BanglaCLIP model to align text and visual representations for\\ncross-modal understanding. [Code]\\n∗ AI-Agent Based Python Learning System: Developed an intelligent tutoring system using LLMs with\\ndynamic content generation, real-time code feedback, and automated grade reporting to personalize programming\\neducation experiences. [Code]\\n∗ AI-Agent Based Music Analysis Application: Created an AI-driven system that analyzes instrumentation,\\nmusical features, and predicts virality potential using LLMs and YAMNet. Provides detailed insights into music\\ncomposition and trends for creators and analysts. [Code]\\n∗ Disaster Tweet Detection: Implemented an LSTM model in TensorFlow to automatically detect\\ndisaster-related tweets for emergency response analysis and real-time monitoring. [Code]\\n∗ Hate Speech Detection in Bengali: Developed ML and DL models to detect hate speech in Bengali text\\nwritten in English script, leveraging advanced NLP techniques for accurate classification. [Code]\\n∗ Rice Disease Detection: Built an ensemble model combining EfficientNet and Vision Transformer (ViT)\\narchitectures for accurate multi-disease classification in rice plants with high precision. [Code]\\n∗ Hospital Management System: Developed a comprehensive hospital management system using Java,\\nstreamlining patient records, appointment scheduling, and billing processes for efficient healthcare administration.\\n[Code]\\n∗ Animal Care Mobile App: Created a Flutter-based mobile application for comprehensive animal care services,\\nenabling users to book veterinary appointments, search for pet adoptions, and make donations to pet shops.\\n[Code]\\nCo-curricular Experience\\nCompetitive Programming| 2021 – May 2024\\n∗ Learnt various algorithms and data structures on graphs, trees, number theory, and dynamic programming.\\nSolved 100+ problems on online platforms such as Codeforces and Leetcode.\\n∗ Participated in various programming competitions on online platforms.\\nIEEE CS BDC Spark Administration Management| 2021 – May 2024\\n∗ Organized technical seminars, workshops, and competitions. Responsible for academic event planning, workshop\\ndesign, and managing conferences.\\n∗ Played a role in organizing several inter-university events with 200+ participants.\\nVice Chair/Secretary| IEEE Computer Society ULAB Student Branch Chapter Feb 2020 – April 2023\\n∗ Organized and led 30+ technical seminars, workshops, and competitions, demonstrating strong leadership and\\nevent management skills.\\n∗ Supported organization of inter-university events with 100+ participants.\\nTechnical Skills\\nLanguages: Java, Python, C/C++, SQL, HTML/CSS, JavaScript, Dart, Flutter\\nFrameworks: PyTorch, Keras, Flask, FastAPI, Gradio, Langchain, OpenCV\\nDeveloper Tools: Git, Tableau, Google Colab, Visual Studio, PyCharm, Docker\\nLibraries: pandas, NumPy, Matplotlib, Scikit-learn', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e324ec1c-c8c9-44f2-a0da-597844b34796', embedding=None, metadata={'page_label': '1', 'file_name': 'Monira Updated CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Monira Updated CV.pdf', 'file_type': 'application/pdf', 'file_size': 408295, 'creation_date': '2025-11-05', 'last_modified_date': '2025-10-28'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='  \\nMonira Akter          \\nAddress:   Holdings: 14, Mitali Road, Road- 15(Old) \\n                   8/A (New) Dhanmondi, Dhaka-1209. \\nMobile:     (+88) 01717615668 \\nE-mail:       moniraakter3103@gmail.com  \\nLinkedIn:  http://linkedin.com/in/monira-akter-b5a05b2a8/ \\n \\nCareer Summary:  \\nA Computer Science major and BBA minor student from the University of Liberal Arts Bangladesh. My interests lie in creating \\nand implementing curriculum and extracurricular activities that drive me  to solve problems. As an individual, I am strongly \\ncommitted to continuous learning and always looking forward to seeking knowledge and experience to benefit both my practical \\nand personal growth. \\n \\nCareer Objective: \\nEager to learn and contribute to the IT Sector by bringing honesty, creativity, and openness to teamwork. Excited to adapt, try \\nnew ideas, and create meaningful results while growing with the organization.  \\n \\nKey Proficiencies:  \\n\\uf0b7 Team Leadership and collaboration. \\n\\uf0b7 Expertise in Microsoft Office and Google Suite \\n(Microsoft Word, Excel, PowerPoint, Outlook, \\nGoogle Sheets, and Excel). \\n\\uf0b7 Programming Languages: C, C++, Java,Python. \\n \\n\\uf0b7 Machine Learning & AI: Prompt Engineering, \\nNLP, Model   Fine -tuning, Transformers (GPT, \\nBERT, DistilBART), Data Handling. \\n\\uf0b7 Web Development experience with HTML, CSS, \\nand PHP. \\nAcademic Qualification:  \\n \\nB.Sc. in Computer Science and Engineering, University of Liberal Arts Bangladesh (ULAB)  \\nCGPA: 3.72 (Current)  \\nHigher Secondary Certificate (H.S.C.), Birshreshtha Noor Mohammad Public College  \\nGPA: 5.00  \\nSecondary School Certificate (S.S.C.), Birshreshtha Noor Mohammad Public College \\nGPA: 5.00  \\nCo-curricular activities:  \\n        ● Working as a President in the ULAB YES Club.  \\n● Peer Mentor in ULAB Student Affairs Office.  \\n● Admission Ambassador in the ULAB Admission Office.  \\n● Campus Ambassador at Teach for Bangladesh, Netcom Learning, and Lead Academy.  \\n● Attended ULAB 7th Convocation as an active volunteer.  \\n● Participated in Business Case Competitions: Idea Ignite (Runners-up), Idea Hunters 4.0 (Finalist and only \\nselected team from ULAB), and Hult Prize.  \\n● Active club member of the ULAB Nutrition and Wellness Club.  \\n      \\nLanguage Skill:  Effective verbal and written communication skills in both English and Bengali. \\n \\nReferences: \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n    \\n \\n                            \\nSignature:  \\n      \\n                                                                                           \\nDeclaration:   \\nI hereby declare that all the information stated above is correct and I have all the necessary Documents to support the \\ninformation have provided. \\nMd. Raihan Kibria \\nSenior Lecturer, School of Engineering \\nUniversity of Liberal Arts Bangladesh \\nMobile: 01819417956 \\nEmail:raihan.kibria@ulab.edu.bd \\n \\n \\n Md.Robiul Hassan \\nAssistant Manager, HR \\nSaudia Cargo \\nMobile: 01615222254 \\nEmail:robiulhassan2254@gmail.com \\n ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b6a6a1ee-ba0b-4898-a2a3-9146949af3f6', embedding=None, metadata={'page_label': '', 'file_name': 'Orthee_CV.pdf', 'file_path': 'g:\\\\Ongoing Project\\\\RAG with  LLAMA\\\\artifacts\\\\Orthee_CV.pdf', 'file_type': 'application/pdf', 'file_size': 154920, 'creation_date': '2025-11-05', 'last_modified_date': '2025-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Urbana Jaman Orthee\\n/githubGithub| /linkedinUrbana| /gl⌢beurbana-jaman.com| /envel⌢peurbanajaman.orthee@gmail.com| ♂¶obile+880 1832 242121\\nSUMMARY\\nPassionate and detail-oriented Computer Science under-\\ngraduate witha strong foundationin machine learning, data\\nanalysis, and software development. Skilled in Python-\\nbased ML frameworks and data-driven problem solving,\\nwith hands-on experience in building predictive and ana-\\nlytical models. Interested in applying AI and data science\\ntechniques to create impactful, real-world solutions across\\ndiverse domains.\\nRESEARCH INTERESTS\\n•Transformers and Deep Learning\\n•Time-Series Forecasting and Sensor Data\\n•Agentic AI (LangChain, LangGraph)\\n•Ethical AI and Machine Unlearning\\n•LLM Evaluation and Model Optimization\\nEDUCATION\\nB.Sc. in Computer Science and Engineering\\nUniversity of Liberal Arts Bangladesh\\nMajor: Data Science\\nGPA:3.93 / 4.00\\n2022 – Present\\nRelevant Courses:Artificial Intelligence & Machine\\nLearning, Statistics & Probability, Data Structures & Al-\\ngorithms, Database Management Systems, IoT Systems\\nTECHNICAL SKILLS\\nLanguages & Libraries:Python (NumPy, Pandas, Mat-\\nplotlib, Scikit-learn, PyTorch, TensorFlow)\\nAI/ML Expertise:Transformers, Time-Series Forecast-\\ning, NLP, Deep Learning, Model Evaluation\\nFrameworks & Tools:LangChain, MLflow, Git, Linux,\\nVS Code, LaTeX\\nConcepts:Data Preprocessing, Feature Engineering,\\nModel Fine-tuning, Experiment Tracking\\nCERTIFICATIONS\\nThe Arduino Platform and C Programming– UC\\nIrvine (Apr 2025)\\nWeb Development with HTML, CSS, JS– IBM (Feb\\n2025)\\nIoT Devices– University of Illinois (Nov 2024)\\nData Science Math Skills– Duke University (Nov 2024)\\nLANGUAGES\\nBengali■ ■ ■ ■ ■(Native)\\nEnglish■ ■ ■ ■ ❏(Fluent)\\nHindi■ ■ ■ ❏ ❏(Intermediate)\\nAI & RESEARCH PROJECTS\\nCardiovascular Disease Classification – AI Project\\n2024\\nDeveloped a predictive model to detect cardiovascular risk\\nbased on medical indicators such as cholesterol, BMI, and\\nblood pressure. Compared Logistic Regression, Random\\nForest, and XGBoost models, achieving 91% classification\\naccuracy through hyperparameter optimization.\\nTech: Python, Pandas, Scikit-learn, XGBoost, Matplotlib\\nFocus: Medical ML, Classification, Model Evaluation\\nStudent Performance Prediction Analysis – Aca-\\ndemic Project2025\\nApplied ML models to predict student academic outcomes\\nusing demographic and socio-economic data. Conducted\\nEDA, feature selection, and compared regression and clas-\\nsification models. Provided data-driven insights for perfor-\\nmance improvement.\\nTech: Python, Pandas, Scikit-learn, Seaborn\\nFocus: Predictive Analytics, Feature Importance, EDA\\nAgentic AI Workflow Simulation – Experimental\\nStudy2025\\nImplemented multi-agent workflows using LangChain for\\nautomated summarization and decision-making. Designed\\nLLMchains toperformcontext-basedtaskcoordinationand\\nreport generation.\\nTech: LangChain, Python, OpenAI API\\nFocus: Agentic AI, Automation, Model Chaining\\nMachine Unlearning – Final Year Research Project\\n2025\\nExplored selective forgetting mechanisms to enhance data\\nprivacy in ML models. Designed retraining strategies and\\nevaluated the impact of data removal on generalization.\\nTech: Python, Scikit-learn\\nFocus: Ethical AI, Privacy Preservation\\nEXPERIENCE\\nTeaching Assistant (TA)Sep 2025 – Present\\nUniversity of Liberal Arts Bangladesh\\nAssisted students in Data Science and ML labs. Supported\\ndebugging, model evaluation, and project-based learning\\nsessions.\\nPrivate TutorOct 2020 – Present\\nGuided students in programming and analytical problem-\\nsolving. Focused on technical writing and algorithmic rea-\\nsoning.\\nREFERENCE\\nDr. Nafees Mansoor, PhD\\nAssociate Professor, Dept. of CSE\\nUniversity of Liberal Arts Bangladesh\\nEmail: nafees.mansoor@ulab.edu.bd', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9ad18f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.langchain import LangchainEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2235f580",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a QA asistant .\n",
    " Your goal is to answer question as accurately\n",
    " as possible based on the\n",
    " instruction and context provided .\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ed11238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "508d8884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:07:05,514 - INFO - Load pretrained SentenceTransformer: intfloat/e5-large-v2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0ae985e4424a29995f7f754a125afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/387 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\TAZIM\\AppData\\Local\\llama_index\\llama_index\\Cache\\models--intfloat--e5-large-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4f1259e7024edd97c2ff9efbb5e4ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d705ee1dc257415fb1d80757063477cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4d42b318c4a45c4acc52e3e9b7ec742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/616 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "2025-11-09 21:07:09,896 - WARNING - Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb389d7317a7400c94de4fde88084d42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f5ec8afd5f54bef91e7865e9efc5ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f27a919c17b46b0ae6e309bb548c98a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8810fa626414ab68c58260eeb2db648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d23a63501a094adeb44172fa42e64153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "824df8d6e36c432c98e6d834b81a4642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/201 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 21:16:59,258 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "# # 1. Load embeddings from LangChain\n",
    "# hf_embed = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# # 2. Wrap them for LlamaIndex\n",
    "# embed_model = LangchainEmbedding(hf_embed)\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"intfloat/e5-large-v2\",\n",
    "    max_length=512,\n",
    "    device=\"cpu\",  # or \"cuda\"\n",
    "    embed_batch_size=32,  # controls batching\n",
    "    # DO NOT pass normalize_embeddings here\n",
    ")\n",
    "\n",
    "# 3. Load Ollama LLM\n",
    "llm = Ollama(model=\"llama3.2:1b\",system_prompt=system_prompt,temperature=0.0,max_tokens=1000)\n",
    "\n",
    "# 4. Load your documents\n",
    "docs = SimpleDirectoryReader(\"artifacts/\").load_data()\n",
    "\n",
    "\n",
    "Settings.chunk_size = 512\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# 5. Build the vector index\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f32dacc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 22:32:01,376 - INFO - HTTP Request: POST http://localhost:11434/api/show \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "llm = Ollama(model=\"phi3.5:latest\",system_prompt=system_prompt,temperature=0.2,max_tokens=2000)\n",
    "\n",
    "# 4. Load your documents\n",
    "docs = SimpleDirectoryReader(\"artifacts/\").load_data()\n",
    "\n",
    "\n",
    "Settings.chunk_size = 1024\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.TOP_K = 3\n",
    "Settings.chunk_overlap = 128\n",
    "\n",
    "# 5. Build the vector index\n",
    "index = VectorStoreIndex.from_documents(docs)\n",
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "91c4c556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: llama-index\n",
      "Version: 0.14.7\n",
      "Summary: Interface between LLMs and your data\n",
      "Home-page: https://llamaindex.ai\n",
      "Author: \n",
      "Author-email: Jerry Liu <jerry@llamaindex.ai>\n",
      "License-Expression: MIT\n",
      "Location: G:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\n",
      "Requires: llama-index-cli, llama-index-core, llama-index-embeddings-openai, llama-index-indices-managed-llama-cloud, llama-index-llms-openai, llama-index-readers-file, llama-index-readers-llama-parse, nltk\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show llama-index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "16570586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from llama_index.core.text_splitter import SentenceSplitter\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "Settings.chunk_size = 1024\n",
    "Settings.chunk_overlap = 128\n",
    "Settings.llm_temperature = 0.0\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "Settings.similarity_top_k = 5\n",
    "Settings.response_mode = \"compact\"\n",
    "Settings.node_postprocessors = [SimilarityPostprocessor(similarity_cutoff=0.75)]\n",
    "# Settings.text_splitter = SemanticSplitter(chunk_size=1024, chunk_overlap=128)\n",
    "Settings.system_prompt = \"You are a factual assistant. Use only the retrieved data to answer.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "58404768",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6c60c13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-09 22:32:19,019 - INFO - HTTP Request: POST http://localhost:11434/api/chat \"HTTP/1.1 500 Internal Server Error\"\n"
     ]
    },
    {
     "ename": "ResponseError",
     "evalue": "model requires more system memory than is currently available unable to load full model on GPU (status code: 500)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[146]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mquery_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat are the machine learning projects mentioned in the tazim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43ms CV?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:44\u001b[39m, in \u001b[36mBaseQueryEngine.query\u001b[39m\u001b[34m(self, str_or_query_bundle)\u001b[39m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m     43\u001b[39m         str_or_query_bundle = QueryBundle(str_or_query_bundle)\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     query_result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m dispatcher.event(\n\u001b[32m     46\u001b[39m     QueryEndEvent(query=str_or_query_bundle, response=query_result)\n\u001b[32m     47\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\query_engine\\retriever_query_engine.py:197\u001b[39m, in \u001b[36mRetrieverQueryEngine._query\u001b[39m\u001b[34m(self, query_bundle)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.callback_manager.event(\n\u001b[32m    194\u001b[39m     CBEventType.QUERY, payload={EventPayload.QUERY_STR: query_bundle.query_str}\n\u001b[32m    195\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m query_event:\n\u001b[32m    196\u001b[39m     nodes = \u001b[38;5;28mself\u001b[39m.retrieve(query_bundle)\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_response_synthesizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynthesize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m     query_event.on_end(payload={EventPayload.RESPONSE: response})\n\u001b[32m    203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\base.py:235\u001b[39m, in \u001b[36mBaseSynthesizer.synthesize\u001b[39m\u001b[34m(self, query, nodes, additional_source_nodes, **response_kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m     query = QueryBundle(query_str=query)\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._callback_manager.event(\n\u001b[32m    232\u001b[39m     CBEventType.SYNTHESIZE,\n\u001b[32m    233\u001b[39m     payload={EventPayload.QUERY_STR: query.query_str},\n\u001b[32m    234\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m event:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m     response_str = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmetadata_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMetadataMode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLLM\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnodes\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m     additional_source_nodes = additional_source_nodes \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[32m    244\u001b[39m     source_nodes = \u001b[38;5;28mlist\u001b[39m(nodes) + \u001b[38;5;28mlist\u001b[39m(additional_source_nodes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\compact_and_refine.py:43\u001b[39m, in \u001b[36mCompactAndRefine.get_response\u001b[39m\u001b[34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# use prompt helper to fix compact text_chunks under the prompt limitation\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# TODO: This is a temporary fix - reason it's temporary is that\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# the refine template does not account for size of previous answer.\u001b[39;00m\n\u001b[32m     42\u001b[39m new_texts = \u001b[38;5;28mself\u001b[39m._make_compact_text_chunks(query_str, text_chunks)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_response\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtext_chunks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_texts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprev_response\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprev_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:179\u001b[39m, in \u001b[36mRefine.get_response\u001b[39m\u001b[34m(self, query_str, text_chunks, prev_response, **response_kwargs)\u001b[39m\n\u001b[32m    175\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m text_chunk \u001b[38;5;129;01min\u001b[39;00m text_chunks:\n\u001b[32m    176\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prev_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    177\u001b[39m         \u001b[38;5;66;03m# if this is the first chunk, and text chunk already\u001b[39;00m\n\u001b[32m    178\u001b[39m         \u001b[38;5;66;03m# is an answer, then return it\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_give_response_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m            \u001b[49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\n\u001b[32m    181\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    183\u001b[39m         \u001b[38;5;66;03m# refine response if possible\u001b[39;00m\n\u001b[32m    184\u001b[39m         response = \u001b[38;5;28mself\u001b[39m._refine_response_single(\n\u001b[32m    185\u001b[39m             prev_response, query_str, text_chunk, **response_kwargs\n\u001b[32m    186\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:241\u001b[39m, in \u001b[36mRefine._give_response_single\u001b[39m\u001b[34m(self, query_str, text_chunk, **response_kwargs)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._streaming:\n\u001b[32m    238\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    239\u001b[39m         structured_response = cast(\n\u001b[32m    240\u001b[39m             StructuredRefineResponse,\n\u001b[32m--> \u001b[39m\u001b[32m241\u001b[39m             \u001b[43mprogram\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcontext_str\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcur_text_chunk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    244\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    245\u001b[39m         )\n\u001b[32m    246\u001b[39m         query_satisfied = structured_response.query_satisfied\n\u001b[32m    247\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m query_satisfied:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\response_synthesizers\\refine.py:85\u001b[39m, in \u001b[36mDefaultRefineProgram.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m     83\u001b[39m         answer = answer.model_dump_json()\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m     answer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_llm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m StructuredRefineResponse(answer=answer, query_satisfied=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\llms\\llm.py:623\u001b[39m, in \u001b[36mLLM.predict\u001b[39m\u001b[34m(self, prompt, **prompt_args)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metadata.is_chat_model:\n\u001b[32m    622\u001b[39m     messages = \u001b[38;5;28mself\u001b[39m._get_messages(prompt, **prompt_args)\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m     chat_response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m     output = chat_response.message.content \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index_instrumentation\\dispatcher.py:335\u001b[39m, in \u001b[36mDispatcher.span.<locals>.wrapper\u001b[39m\u001b[34m(func, instance, args, kwargs)\u001b[39m\n\u001b[32m    332\u001b[39m             _logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    334\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio.Future):\n\u001b[32m    337\u001b[39m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[32m    338\u001b[39m         new_future = asyncio.ensure_future(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:175\u001b[39m, in \u001b[36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat\u001b[39m\u001b[34m(_self, messages, **kwargs)\u001b[39m\n\u001b[32m    166\u001b[39m event_id = callback_manager.on_event_start(\n\u001b[32m    167\u001b[39m     CBEventType.LLM,\n\u001b[32m    168\u001b[39m     payload={\n\u001b[32m   (...)\u001b[39m\u001b[32m    172\u001b[39m     },\n\u001b[32m    173\u001b[39m )\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m175\u001b[39m     f_return_val = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_self\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    177\u001b[39m     callback_manager.on_event_end(\n\u001b[32m    178\u001b[39m         CBEventType.LLM,\n\u001b[32m    179\u001b[39m         payload={EventPayload.EXCEPTION: e},\n\u001b[32m    180\u001b[39m         event_id=event_id,\n\u001b[32m    181\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\llama_index\\llms\\ollama\\base.py:394\u001b[39m, in \u001b[36mOllama.chat\u001b[39m\u001b[34m(self, messages, **kwargs)\u001b[39m\n\u001b[32m    391\u001b[39m think = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mthink\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.thinking\n\u001b[32m    392\u001b[39m \u001b[38;5;28mformat\u001b[39m = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mformat\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.json_mode \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m394\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mollama_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m    \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    405\u001b[39m response = \u001b[38;5;28mdict\u001b[39m(response)\n\u001b[32m    407\u001b[39m blocks: List[TextBlock | ThinkingBlock | ToolCallBlock] = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\ollama\\_client.py:351\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, format, options, keep_alive)\u001b[39m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    307\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    308\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    316\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    317\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    318\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    319\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    320\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    349\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    350\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m351\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    363\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    364\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\ollama\\_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mg:\\Ongoing Project\\RAG with  LLAMA\\venv\\Lib\\site-packages\\ollama\\_client.py:133\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    135\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: model requires more system memory than is currently available unable to load full model on GPU (status code: 500)"
     ]
    }
   ],
   "source": [
    "response = query_engine.query(\"what are the machine learning projects mentioned in the tazim's CV?\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
